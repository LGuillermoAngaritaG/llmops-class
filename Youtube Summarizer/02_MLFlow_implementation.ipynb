{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Video Summarizer with MLflow Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a YouTube video summarization chain\n",
    "2. Track the chain and prompts using MLflow\n",
    "3. Load and use the tracked model\n",
    "\n",
    "## Setup and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install youtube-transcript-api groq python-dotenv mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import mlflow\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Groq client\n",
    "client = groq.Groq(\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Chain Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class YouTubeSummaryChain:\n",
    "    def __init__(self, model_name: str = \"mixtral-8x7b-32768\", temperature: float = 0.3):\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.prompt_template = \"\"\"\n",
    "        Please provide a comprehensive summary of the following video transcript. \n",
    "        Focus on the main points, key insights, and important conclusions:\n",
    "\n",
    "        {text}\n",
    "\n",
    "        Please structure the summary with:\n",
    "        1. Main Topic/Theme\n",
    "        2. Key Points\n",
    "        3. Important Details\n",
    "        4. Conclusions\n",
    "        \"\"\"\n",
    "    \n",
    "    def extract_video_id(self, url: str) -> str:\n",
    "        \"\"\"Extract YouTube video ID from URL\"\"\"\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "        return None\n",
    "\n",
    "    def get_transcript(self, video_id: str) -> str:\n",
    "        \"\"\"Get transcript for a YouTube video\"\"\"\n",
    "        try:\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            return ' '.join([t['text'] for t in transcript_list])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "    def summarize_text(self, text: str) -> str:\n",
    "        \"\"\"Summarize text using Groq\"\"\"\n",
    "        prompt = self.prompt_template.format(text=text)\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=2048\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __call__(self, url: str) -> str:\n",
    "        \"\"\"Process a YouTube URL and return summary\"\"\"\n",
    "        video_id = self.extract_video_id(url)\n",
    "        if not video_id:\n",
    "            return \"Invalid YouTube URL\"\n",
    "        \n",
    "        transcript = self.get_transcript(video_id)\n",
    "        if not transcript:\n",
    "            return \"Could not retrieve transcript\"\n",
    "        \n",
    "        summary = self.summarize_text(transcript)\n",
    "        if not summary:\n",
    "            return \"Could not generate summary\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get chain configuration for MLflow tracking\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"prompt_template\": self.prompt_template\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def log_chain_to_mlflow(chain: YouTubeSummaryChain, experiment_name: str = \"youtube-summarizer\"):\n",
    "    \"\"\"Log the chain configuration and prompt to MLflow\"\"\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters\n",
    "        config = chain.get_config()\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": config[\"model_name\"],\n",
    "            \"temperature\": config[\"temperature\"]\n",
    "        })\n",
    "        \n",
    "        # Log prompt template as artifact\n",
    "        with open(\"prompt_template.txt\", \"w\") as f:\n",
    "            f.write(config[\"prompt_template\"])\n",
    "        mlflow.log_artifact(\"prompt_template.txt\")\n",
    "        \n",
    "        # Log the chain as a custom model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"youtube_summarizer\",\n",
    "            python_model=chain,\n",
    "            artifacts={\"prompt_template\": \"prompt_template.txt\"},\n",
    "            code_path=[\".\"]  # Include current directory in the model\n",
    "        )\n",
    "        \n",
    "        return run.info.run_id\n",
    "\n",
    "def load_chain_from_mlflow(run_id: str) -> YouTubeSummaryChain:\n",
    "    \"\"\"Load a chain from MLflow\"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/youtube_summarizer\"\n",
    "    chain = mlflow.pyfunc.load_model(model_uri)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create and log the chain\n",
    "chain = YouTubeSummaryChain()\n",
    "run_id = log_chain_to_mlflow(chain)\n",
    "print(f\"Chain logged with run_id: {run_id}\")\n",
    "\n",
    "# Load the chain\n",
    "loaded_chain = load_chain_from_mlflow(run_id)\n",
    "\n",
    "# Use the loaded chain\n",
    "youtube_url = \"https://www.youtube.com/watch?v=your_video_id\"\n",
    "summary = loaded_chain(youtube_url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow Experiment Results\n",
    "\n",
    "You can view the tracked experiments by running:\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "This will start the MLflow UI server where you can see:\n",
    "1. All experiment runs\n",
    "2. Chain configurations\n",
    "3. Prompt templates\n",
    "4. Performance metrics (if added)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
